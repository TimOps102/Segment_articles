{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d1b17d",
   "metadata": {},
   "source": [
    "# Adjustment of the segmentation of Eynollah to merge whole articles and adjust the reading order \n",
    "\n",
    "In this notebook, we try to adapt the edition of Eynollah to the layout of the \"Freedom Struggle\" from 1936 in order to recognize whole on a page. The goal is to recognize the whole article, i.e. the headline and the appropriate text regions below it. This turns out to be a non-trivial task especially with historical newspapers as the reading order is not always intuitively the same. \n",
    "Afterwards, a full text indexing of the articles could be performed with an OCR pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a2694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "path= \"croped/\"\n",
    "output= \"croped_colored/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56c277fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_small(dic):\n",
    "    \"\"\"Delete all textregions which are too small. They are probably errors from the segmentation step\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dic:  dicitonary\n",
    "        key:    is the name of the textregion (in the format: \"region_00xx\")\n",
    "        values: Its a list. List[0] contains all coordinates which the segmentor recognized as textarea. List[1] is the reading order\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    new_dic: dictionary\n",
    "        Is the same format like the param \"dic\", but now has a few entrys less.  \n",
    "    \"\"\"\n",
    "    \n",
    "    dic = dict(sorted(dic.items(), key=lambda item: int(item[1][1]))) #sort by reading order\n",
    "    new_dic = {}\n",
    "\n",
    "    count = 0 \n",
    "    for k,v in dic.items():\n",
    "        start,end = get_start_end(v[0])\n",
    "        \n",
    "        area = (end[0]-start[0])*(end[1]-start[1]) #calculate area of rectangle\n",
    "        \n",
    "        #delete regions which have an area smaller then a certain area\n",
    "        if area <= 1500:\n",
    "            count +=1\n",
    "            continue\n",
    "        else:\n",
    "            new_dic[k] = [v[0],int(v[1])-count]\n",
    "\n",
    "    return new_dic\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b81c1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_start_end(coord_list):\n",
    "    \n",
    "    \"\"\"Gets the top left corner and the right bottom corner of each bounding box. The coordinate system start in the left top corner of a picture (0,0).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coord_list : str\n",
    "        Its a list of coordinates from a Page-XML file for the region of text (polygonomial).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    start:\n",
    "        a tuple of the smallest x and y value of the region (top left corner)\n",
    "    end:\n",
    "        a tuple of the maximum x and y value of the region (bottom right corner)\n",
    "    \"\"\"\n",
    "    \n",
    "    coord_list = coord_list.split(\" \")\n",
    "    coord_list = [tuple(map(int,tuple(x.split(\",\")))) for  x in coord_list]\n",
    "    x_max = max(coord_list,key=lambda x:x[0])\n",
    "    x_min = min(coord_list,key=lambda x:x[0])\n",
    "    y_max = max(coord_list,key=lambda x:x[1])\n",
    "    y_min = min(coord_list,key=lambda x:x[1])\n",
    "        \n",
    "        \n",
    "    ## Coordinate System starts in the top left corner of the picture!\n",
    "    start = (x_min[0],y_min[1])\n",
    "    end = (x_max[0], y_max[1])\n",
    "    \n",
    "    return start,end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c67d65c",
   "metadata": {},
   "source": [
    "## The next functions are used to combine text regions within a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dc3c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_regions_in_column(dic,textlines):\n",
    "    \n",
    "    \"\"\"This function combines textregions (boundingboxes) in one column, which have nearly the same x values on the left and right side, and a small y distance between two regions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dic:  dicitonary\n",
    "        key:    is the name of the textregion (in the format: \"region_00xx\")\n",
    "        values: Its a list. List[0] contains all coordinates which the segmentor recognized as textarea. List[1] is the reading order\n",
    "    textlines: dictionary\n",
    "        key:    Names of the textregions in the PAGE-XML\n",
    "        values: A list. List[0] contains the Name of the textregion and a suffix for the line number (e.g. region_0053_line_0001). List[1] are the coordinates of the bounding box of the textline\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    new_dic: \n",
    "        key:    New Ids for the new reading order\n",
    "        values  A list of strings, which have the name of the textregions, which are now combined in one bigger region. \n",
    "    \"\"\"\n",
    "    \n",
    "    dic = dict(sorted(dic.items(), key=lambda item: int(item[1][1]))) #sort by reading order\n",
    "    new_dic = {}\n",
    "   \n",
    "    count = 0\n",
    "    \n",
    "    for i,(k,v) in enumerate(list(dic.items())):\n",
    "       \n",
    "    \n",
    "        #two dummyelements for very first and the very last textregion on the page\n",
    "        if i==0:\n",
    "            last_entry = [0,[\"0,0\",0]]\n",
    "        else:\n",
    "            last_entry = list(dic.items())[i-1]\n",
    "        \n",
    "        if i==len(dic.items())-1:\n",
    "            next_entry = [0,[\"0,0\",0]]\n",
    "        else:\n",
    "            next_entry = list(dic.items())[i+1]\n",
    "        \n",
    "        \n",
    "        #here we calculate the top left and bottom right points for the last, the present and the next bounding bos\n",
    "        start,end = get_start_end(v[0])\n",
    "        n_start, n_end = get_start_end(next_entry[1][0])\n",
    "        l_start, l_end = get_start_end(last_entry[1][0])\n",
    "        \n",
    "        \n",
    "       \n",
    "        if check_if_near(start[0],n_start[0], end[0], n_end[0], abs(end[1]-n_start[1])) and (int(v[1])+1 == next_entry[1][1]) and not is_one_liner(k, textlines):\n",
    "           \n",
    "            if count not in new_dic:\n",
    "                \n",
    "                new_dic[count]=[k]\n",
    "            else: \n",
    "                new_dic[count].append(k)\n",
    "        \n",
    "        elif check_if_near(l_start[0],start[0], l_end[0], end[0], abs(l_end[1]-start[1])) and (int(v[1])-1 == last_entry[1][1]) and not is_one_liner(k, textlines):\n",
    "            if count not in new_dic:\n",
    "                \n",
    "                new_dic[count]=[k]\n",
    "            else: \n",
    "                new_dic[count].append(k)\n",
    "            \n",
    "            count+=1\n",
    "        else:\n",
    "            count+=1\n",
    "            new_dic[count]=[k]\n",
    "            count+=1\n",
    "     \n",
    "    #rename the keys of the dictionary for a new clean order\n",
    "    new_dic = {index: value for index, (_, value) in enumerate(new_dic.items())}\n",
    "    \n",
    "    new_dic = possible_headline_in_column(dic, new_dic)\n",
    "    \n",
    "    new_dic = {index: value for index, (_, value) in enumerate(new_dic.items())}\n",
    "    \n",
    "    return new_dic\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75da3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_if_near(top_left, next_top_left, bottom_right, next_bottom_right,height_dist):\n",
    "    \"\"\"Check if two boundingboxes (above each other) with certain x and y values are near to each other\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    top_left: int\n",
    "        x-coordinate of the top left of the upper bounding box\n",
    "    next_top_left: int\n",
    "        x-coordinate of the top left of the lower bounding box\n",
    "    bottom_right: int\n",
    "        x-coordinate of the bottom right of the upper bounding box\n",
    "    next_bottom_right: int\n",
    "        x-coordinate of the bottom right of the lower bounding box\n",
    "    height_dist: int\n",
    "        distance between the y-coordinate of the bottom right_corner of the upper bounding box and the y-coordinate of the top left corner of the lower boundingbox\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    True:\n",
    "        If two boundingboxes are in the same column and have nearly the same x values on the left and right side and the distance between is very small\n",
    "    False:\n",
    "        If not so.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if (abs(top_left-next_top_left) + abs(bottom_right-next_bottom_right) <250) and height_dist <20:\n",
    "     \n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7f10ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_one_liner(region,textlines):\n",
    "    \"\"\"Checks if a textregions only consists of one line. Which means it is possibly a headline\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    region:  string\n",
    "        Name of the textregion in the PAGE-XML\n",
    "    textlines: dictionary\n",
    "        key:    Names of the textregions in the PAGE-XML\n",
    "        values: A list. List[0] contains the Name of the textregion and a suffix for the line number (e.g. region_0053_line_0001). List[1] are the coordinates of the bounding box of the textline\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    True\n",
    "        if the textregion has more then one line\n",
    "    False\n",
    "        if the textregion has just one line or is not in the textline dictionary(which mean it could be a picture or something else)\n",
    "        \n",
    "    \"\"\"\n",
    "    if region in textlines:\n",
    "        if len(textlines[region])==1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9daede51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def possible_headline_in_column(dic, combined):\n",
    "    \n",
    "    \"\"\"This function checks if one, two or three textregions above other textregions could be a title and a subtitle, but only for one column headlines!\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dic:  dicitonary\n",
    "        key:    is the name of the textregion in the Page-XML (in the format: \"region_00xx\")\n",
    "        values: Its a list. List[0] contains all coordinates which the segmentor recognized as textarea. List[1] is the reading order\n",
    "    combined: dictionary\n",
    "        key:    Readingorder ID for the textregions\n",
    "        values: Its a list. The list contains the regions of already combined regions (from heuristics before)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    new: \n",
    "        a dictionary quite similar to the dictionary \"combined\". But now possible headers and there matching textareas are combined in one entry in the dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    new = {k:v for k,v in combined.items()}\n",
    "    \n",
    "    \n",
    "    for i,(k,v) in enumerate(list(combined.items())):\n",
    "        if i==0:\n",
    "            continue\n",
    "        \n",
    "        last_entry = combined[i-1]\n",
    "        \n",
    "        #skip headlines that are possible multicolumn headlines\n",
    "        start,end = get_start_end(dic[v[0]][0])\n",
    "        if end[0]-start[0] > 420:\n",
    "            continue \n",
    "        \n",
    "        \n",
    "        # in this section we try to combine Title and subtitle. But also Title and text if there is no subtitle\n",
    "        if len(last_entry) == 1:\n",
    "            start_sec,end_sec= get_start_end(dic[v[0]][0])\n",
    "            start_first_headline, end_first_headline = get_start_end(dic[last_entry[0]][0])\n",
    "            \n",
    "            #here you can change the parameters for the headline bounding boxes\n",
    "            if (start_sec[0]-220 <= start_first_headline[0] <= end_sec[0]) and (start_sec[0] <= end_first_headline[0] <= start_sec[0]+400) and (abs(start_first_headline[1]-start_sec[1])<70):\n",
    "                    new[k].insert(0,last_entry[0])\n",
    "                    new[k-1].remove(last_entry[0])\n",
    "        \n",
    "        \n",
    "        #this sections trys to combine a recognized title and subtitle region with the matching textregion\n",
    "        if len(last_entry) == 2:\n",
    "            start_sec,end_sec= get_start_end(dic[v[0]][0])\n",
    "            start_first_headline, end_first_headline = get_start_end(dic[last_entry[0]][0])\n",
    "\n",
    "            if (start_sec[0]-280 <= start_first_headline[0] <= end_sec[0]) and (start_sec[0] <= end_first_headline[0] <= end_sec[0]+40) and (abs(start_first_headline[1]-start_sec[1])<100):\n",
    "                    new[k].insert(0,last_entry[0])\n",
    "                    new[k].insert(1,last_entry[1])\n",
    "                    new[k-1].remove(last_entry[0])\n",
    "                    new[k-1].remove(last_entry[0])\n",
    "        \n",
    "        #here we look at headlines consisting of 3 textregions\n",
    "        if len(last_entry) == 3:\n",
    "            start_sec,end_sec= get_start_end(dic[v[0]][0])\n",
    "            start_first_headline, end_first_headline = get_start_end(dic[last_entry[0]][0])\n",
    "\n",
    "            if (start_sec[0]-200 <= start_first_headline[0] <= end_sec[0]) and (start_sec[0] <= end_first_headline[0] <= end_sec[0]+40) and (abs(start_first_headline[1]-start_sec[1])<100):\n",
    "                    new[k].insert(0,last_entry[0])\n",
    "                    new[k].insert(1,last_entry[1])\n",
    "                    new[k].insert(2,last_entry[2])\n",
    "                    new[k-1].remove(last_entry[0])\n",
    "                    new[k-1].remove(last_entry[0])\n",
    "                    new[k-1].remove(last_entry[0])\n",
    "\n",
    "    new={k: v for k, v in new.items() if len(v)>0} \n",
    "    return new\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b2794",
   "metadata": {},
   "source": [
    "# The next functions first look for multi-column headings and then combine them with the first text section that starts in the upper left corner under the heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56a3c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def possible_headline_multicolumn(dic, combined,textlines):\n",
    "    \n",
    "    \"\"\"This function checks if one or two textregions above other textregions could be a title and a subtitle, but only for multicolumn headlines!\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dic:  dicitonary\n",
    "        key:    Is the name of the textregion of the Page-XML(in the format: \"region_00xx\")\n",
    "        values: Its a list. List[0] contains all coordinates which the segmentor recognized as textarea. List[1] is the reading order\n",
    "    combined: dictionary\n",
    "        key:    Readingorder ID for the textregions, because there are now combined, and the bigger combined regions gets a new id\n",
    "        values: Its a list. The list contains the regions of already combined regions (from heuristics before)\n",
    "    textlines: dictionary\n",
    "        key:    textregion id of the page_xml\n",
    "        values: List of all lines associated to the textregion\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    new: \n",
    "        A dictionary where the values of the keys can be one or more regions which can be seen as headlines\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    avg_height = sum([textline_heights(reg,textlines) for k,v in combined.items() if len(v) > 1 for reg in v ],[])\n",
    "    avg_height = sum(avg_height)/len(avg_height)\n",
    "\n",
    "    \n",
    "    \n",
    "    headlines = []\n",
    "    for k,v in combined.items():\n",
    "        \n",
    "        \n",
    "        if len(v) == 1:   \n",
    "            #check if less then 4 textlines in headline (otherwise probability is high that the region is not a headline)\n",
    "            if v[0] in textlines:\n",
    "                if len(textlines[v[0]])<4:\n",
    "                    bigger = False\n",
    "                    start,end = get_start_end(dic[v[0]][0])\n",
    "                    width=end[0]-start[0]\n",
    "                        \n",
    "                    for line in textline_heights(v[0], textlines):\n",
    "                        #check if the textline are at least 20% higher then the average textline\n",
    "                        if line > (avg_height * 1.2) and width >350:\n",
    "                            bigger = True\n",
    "                        else:\n",
    "                            bigger = False\n",
    "                            break\n",
    "                    if bigger:\n",
    "                        headlines.append(v[0])\n",
    "    \n",
    "    titles={}\n",
    "\n",
    "\n",
    "    for i,title in enumerate(headlines):\n",
    "\n",
    "        if i == 0:\n",
    "            titles[i] = [title]\n",
    "        last_region = headlines[i-1]\n",
    "        last_start,last_end = get_start_end(dic[last_region][0])\n",
    "        start,end = get_start_end(dic[title][0])\n",
    "        \n",
    "        x_diff = abs(start[0]-last_start[0]) + abs(end[0]-last_end[0])\n",
    "        y_diff = abs(last_end[1]-start[1])\n",
    "        \n",
    "        if x_diff < 500 and y_diff < 20:\n",
    "            titles[i] = [last_region,title]\n",
    "            if i!= 0:\n",
    "                del titles[i-1]\n",
    "            \n",
    "        else:\n",
    "            titles[i] = [title]\n",
    "    \n",
    "    titles = {index: value for index, (_, value) in enumerate(titles.items())} \n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10ef50b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def textline_heights(region, textlines):\n",
    "    \n",
    "    \"\"\"Gets the textline heights (the heigths of a bounding box) of one region\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    region:    string\n",
    "        A region of the PAGE-XML\n",
    "    textlines: dictionary\n",
    "        key:    textregion id of the page_xml\n",
    "        values:List of all lines associated to the textregiony)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    heights:   list\n",
    "        A list of all textline-heights (in Pixels) of the textregion\n",
    "    \"\"\"\n",
    "    \n",
    "    heights = []\n",
    "    if region in textlines:\n",
    "        for textline in textlines[region]:\n",
    "            start,end = get_start_end(textline[1])\n",
    "            heights.append(end[1]-start[1])\n",
    "        \n",
    "    return heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "139d3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_multicolumn_text_and_headlines(dic, combined,headlines):\n",
    "    \n",
    "    \"\"\"This function combines a multicolumn headline with the associated textregion beneath it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dic:  dicitonary\n",
    "        key:    Is the name of the textregion of the Page-XML(in the format: \"region_00xx\")\n",
    "        values: Its a list. List[0] contains all coordinates which the segmentor recognized as textarea. List[1] is the reading order\n",
    "    combined: dictionary\n",
    "        key:    Readingorder ID for the textregions, because there are now combined, and the bigger combined regions gets a new id\n",
    "        values: Its a list. The list contains the regions of already combined regions (from heuristics before)\n",
    "    headlines: dictionary\n",
    "        key:    Placeholder IDs. They have no function. \n",
    "        values: List of Strings, which are the regions which belong to the headline\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    new: \n",
    "        A dictionary where now multicolumn headlines and Textregions on the most left column under the title are combined.\n",
    "    \"\"\"\n",
    "    \n",
    "    new = deepcopy(combined)\n",
    "    \n",
    "    for k,v in combined.items():\n",
    "        for key,value in headlines.items():\n",
    "            \n",
    "            if v[0] != value[0]:\n",
    "                start_title, end_title = get_start_end(dic[value[0]][0])\n",
    "                start_text, end_text = get_start_end(dic[v[0]][0])\n",
    "    \n",
    "                x_diff = start_title[0]-start_text[0]\n",
    "                y_diff = start_text[1]-end_title[1]\n",
    "                \n",
    "                if -180 < x_diff < 200 and 0<=y_diff<=100:\n",
    "                    if len(value)==2:\n",
    "                        new[k].insert(0, value[1])\n",
    "                        new[k].insert(0, value[0])\n",
    "                    else:\n",
    "                        new[k].insert(0, value[0])\n",
    "    all_headers = sum(headers.values(),[])\n",
    "    for k,v in new.items():\n",
    "        # here all headlines that are not related to an article get erased. You may want to change that one\n",
    "        if all(elem in all_headers for elem in v):\n",
    "            new[k]=[]\n",
    "    \n",
    "    new = {k: v for k, v in new.items() if len(v)>0} \n",
    "    new = {index: value for index, (_, value) in enumerate(new.items())}\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d0f5c0",
   "metadata": {},
   "source": [
    "# These functions now combine all text regions below a multi-column heading across multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c6717b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns(dic, comb, headers, textlines, separators):\n",
    "    \"\"\"This function combines all columns in one article.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dic:  dicitonary\n",
    "        key:    Is the name of the textregion of the Page-XML(in the format: \"region_00xx\")\n",
    "        values: Its a list. List[0] contains all coordinates which the segmentor recognized as textarea. List[1] is the reading order\n",
    "    comb: dictionary\n",
    "        key:    Readingorder ID for the textregions, because there are now combined, and the bigger combined regions gets a new id\n",
    "        values: Its a list. The list contains the regions of already combined regions (from heuristics before)\n",
    "    headlines: dictionary\n",
    "        key:    Placeholder IDs. They have no function. \n",
    "        values: List of Strings, which are the regions which belong to the headline\n",
    "    textlines: dictionary\n",
    "        key:    textregion id of the page_xml\n",
    "        values: List of all lines associated to the textregion\n",
    "    separators: list\n",
    "        Each element is a string which contains all coordinates from the separator of the PAGE-XML file\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    new_articles: \n",
    "        A dictionary where all columns beneath a multicolumn headline are combined.\n",
    "    \"\"\"\n",
    "\n",
    "    #we create an extra dictionary for the multicolumn articles\n",
    "    articles = {}\n",
    "    count = 0\n",
    "    for k,v in headers.items():\n",
    "        \n",
    "        same_article = False\n",
    "        i = 0\n",
    "        \n",
    "        \n",
    "        while i < len(comb):\n",
    "            \n",
    "            #we need to make a deepcopy, because we dont want to edit the original order\n",
    "            value = deepcopy(comb[i])\n",
    "            \n",
    "            start_head,end_head = get_start_end(dic[v[0]][0])\n",
    "            start_text,end_text = get_start_end(dic[value[0]][0])\n",
    "            \n",
    "            #we save of the coordinates of the last region within the combination headline and first top left paragraphs\n",
    "            if not count in articles:\n",
    "                start_very_last,end_very_last = (0,0),(0,0)\n",
    "            else:\n",
    "                start_very_last,end_very_last = get_start_end(dic[articles[count][-1]][0])\n",
    "                \n",
    "            \n",
    "            #if there is a new region right under it we save it to the article\n",
    "            if (-10 <= start_text[1]-end_very_last[1] <= 60) and (-20 <= start_text[0]-start_very_last[0] <=100):\n",
    "                articles[count].extend(value)\n",
    "\n",
    "            \n",
    "            if v[0] == value[0] or same_article:\n",
    "                \n",
    "                #check if headline or separator (working as article border) is beneath\n",
    "                if check_border(value[-1],headers,separators,dic):\n",
    "\n",
    "                    #same_article is when we detected multiple different regions in one article\n",
    "                    if same_article:\n",
    "                        #when we are here, it means we are at a region which has a border under it and is not directly under the headline (the are already several regions in between (within the same column))\n",
    "                        tmp = i\n",
    "                        i = continue_in_next_column(articles[count],v,dic,comb,textlines)\n",
    "                        if i:\n",
    "                            articles[count].extend(comb[i])\n",
    "                            i+=1\n",
    "                            \n",
    "                        else:\n",
    "                            articles[count].extend(comb[tmp])\n",
    "                            count +=1\n",
    "                            break\n",
    "                    \n",
    "                    else:\n",
    "                        #when we are we are at a paragraph which also has a border under it and is directly under the headline\n",
    "                        articles[count] = comb[i]\n",
    "                        tmp = i\n",
    "                        i = continue_in_next_column(value,v,dic,comb,textlines)\n",
    "                        if i:\n",
    "                            articles[count].extend(comb[i])\n",
    "                            same_article = True\n",
    "    \n",
    "                        else:\n",
    "                            i = tmp\n",
    "                            count += 1\n",
    "                            break\n",
    "                        \n",
    "                else:\n",
    "                    #if we are here we have a paragraph which is not the first under a headline and has no border under it. But it is the same article\n",
    "                    i+=1\n",
    "                    same_article = True\n",
    "                    if count in articles:\n",
    "                        articles[count].extend(value)\n",
    "                    else:\n",
    "                        articles[count]=value\n",
    "                    \n",
    "            else:\n",
    "                i+=1\n",
    "         \n",
    "    \n",
    "    articles = {index: value for index, (_, value) in enumerate(articles.items())}\n",
    "    articles = {key: list(dict.fromkeys(value)) for key,value in articles.items()}\n",
    "    \n",
    "    new_articles = {} \n",
    "    ind=0\n",
    "    \n",
    "    \n",
    "    for comb_key,comb_value in combined.items():\n",
    "        if set(comb_value).issubset(sum(new_articles.values(),[])):\n",
    "            continue\n",
    "        \n",
    "        for art_key, art_value in articles.items():\n",
    "            \n",
    "            if set(comb_value).issubset(art_value):\n",
    "                new_articles[ind] = art_value\n",
    "                break\n",
    "            else:\n",
    "                new_articles[ind] = comb_value\n",
    "        ind +=1\n",
    "    \n",
    "    \n",
    "    return new_articles\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff9a9800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_in_next_column(textregions, header,dic,combined,textlines):\n",
    "    \"\"\"Searches for the next region in the next column within the same article\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    textregions: list\n",
    "        A list of strings of the name of textregions. The whole list depicts an already combined paragraph.\n",
    "    header: list\n",
    "        A list of regions which represented the headings of the related article.  \n",
    "    dic:  dicitonary\n",
    "        key:    Is the name of the textregion of the Page-XML(in the format: \"region_00xx\")\n",
    "        values: Its a list. List[0] contains all coordinates which the segmentor recognized as textarea. List[1] is the reading order\n",
    "    combined: dictionary\n",
    "        key:    Readingorder ID for the textregions, because there are now combined, and the bigger combined regions gets a new id\n",
    "        values: Its a list. The list contains the regions of already combined regions (from heuristics before)\n",
    "    textlines: dictionary\n",
    "        key:    textregion id of the page_xml\n",
    "        values: List of all lines associated to the textregion\n",
    "    separators: list\n",
    "        Each element is a string which contains all coordinates from the separator of the PAGE-XML file\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    k:   int\n",
    "        the reading order number (which is the key of the dictionary \"combined\") for the paragraph which is the first one in the next column under the headline in the same article\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    widths=[]\n",
    "    for k,v in textlines.items():\n",
    "        points = [get_start_end(w[1]) for w in v]\n",
    "        for point in points:\n",
    "            widths.append(point[1][0]-point[0][0])\n",
    "    avg_width = 390\n",
    "    \n",
    "    third_column = False\n",
    "    \n",
    "    start_header,end_header = get_start_end(dic[header[0]][0])\n",
    "    \n",
    "  \n",
    "    first_segment = textregions[len(header)]\n",
    "    start_first, end_first = get_start_end(dic[first_segment][0])\n",
    "    \n",
    "    for k,v in combined.items():\n",
    "        #check if the paragraph in the next column is on the same height as the last one\n",
    "        start_next, end_next = get_start_end(dic[v[0]][0])\n",
    "        \n",
    "        y_diff = abs(start_next[1]-start_first[1])\n",
    "        x_diff = start_next[0] - (start_first[0] + avg_width)\n",
    "\n",
    "        if y_diff <= 100 and -70 <= x_diff <= 70 and (start_header[0] <= start_next[0] <=end_header[0] or end_header[0] <= start_next[0] <=end_header[0] ):\n",
    "            \n",
    "            if v[0] in textregions:\n",
    "                \n",
    "                if third_column:\n",
    "                    avg_width = avg_width * 1.5\n",
    "                else:\n",
    "                    avg_width = avg_width * 2\n",
    "                    third_column = True\n",
    "                    continue\n",
    "            else:\n",
    "                return k\n",
    "    return None\n",
    "    \n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "574ae29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_border(region,headers,separators,dic):\n",
    "    \"\"\"Checks if under a certain region is a border (which means a multicolumn headline, a separator, or the end of the page)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    region: string\n",
    "        the name of the region where we want to look if a border is under it\n",
    "    headers: list\n",
    "        key:    A placeholder Id for the headlines. \n",
    "        values: A list of strings. The list hold all region names which represent the headline\n",
    "    separators: list\n",
    "        Each element is a string which contains all coordinates from the separator of the PAGE-XML file\n",
    "    dic:  dicitonary\n",
    "        key:    Is the name of the textregion of the Page-XML(in the format: \"region_00xx\")\n",
    "        values: Its a list. List[0] contains all coordinates which the segmentor recognized as textarea. List[1] is the reading order\n",
    "\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    boolean  \n",
    "        returns True if a border is under the region.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    sep_list = [get_start_end(sep) for sep in separators]\n",
    "    \n",
    "    head_list = [get_start_end(dic[head][0]) for head in sum(headers.values(),[])]\n",
    "    \n",
    "    start_text,end_text = get_start_end(dic[region][0])\n",
    "    \n",
    "        \n",
    "    \n",
    "    for border in sep_list:\n",
    "        start_border,end_border = border[0],border[1] \n",
    "        y_diff = start_border[1]-end_text[1]\n",
    "        \n",
    "        if -10 <= y_diff <= 100 and ((start_border[0] <= start_text[0] <= end_border[0]) or (start_border[0] <= end_text[0] <= end_border[0])):\n",
    "  \n",
    "            return True\n",
    "    \n",
    "    for border in head_list:\n",
    "        start_border,end_border = border[0],border[1] \n",
    "        y_diff = start_border[1]-end_text[1]\n",
    "        \n",
    "        if -10 <= y_diff <= 150 and ((start_border[0] <= start_text[0] <= end_border[0]) or (start_border[0] <= end_text[0] <= end_border[0])):\n",
    "\n",
    "            return True\n",
    "    \n",
    "    end_of_page = 2700 - end_text[1]\n",
    "    \n",
    "    if end_of_page <= 300:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cee4aa",
   "metadata": {},
   "source": [
    "# Main Part\n",
    "\n",
    "Reading the Page-XML of eynollah, drawing bounding boxes arround recognized textregions and apply some functions to combine those regions to articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b78b2595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "croped_colored/result_croped_00000009.jpg\n",
      "croped_colored/result_croped_00000010.jpg\n",
      "croped_colored/result_croped_00000015.jpg\n",
      "croped_colored/result_croped_00000017.jpg\n",
      "croped_colored/result_croped_00000018.jpg\n",
      "croped_colored/result_croped_00000005.jpg\n",
      "croped_colored/result_croped_00000014.jpg\n",
      "croped_colored/result_croped_00000016.jpg\n",
      "croped_colored/result_croped_00000001.jpg\n",
      "croped_colored/result_croped_00000002.jpg\n",
      "croped_colored/result_croped_00000012.jpg\n",
      "croped_colored/result_croped_00000004.jpg\n",
      "croped_colored/result_croped_00000003.jpg\n",
      "croped_colored/result_croped_00000008.jpg\n",
      "croped_colored/result_croped_00000006.jpg\n"
     ]
    }
   ],
   "source": [
    "count= 1\n",
    "for filename in os.listdir(path):\n",
    "    if not filename.endswith('.xml'): continue\n",
    "    fullname = os.path.join(path, filename)\n",
    "\n",
    "    with open(fullname, 'r') as f:\n",
    "        data = f.read()\n",
    "        data= BeautifulSoup(data, \"xml\")\n",
    "        \n",
    "        #extract Text regions from the PAGE-XML\n",
    "        regions = data.find_all(\"TextRegion\")\n",
    "        #extract Separatorregions from PAGE-XML\n",
    "        separator_list = data.find_all(\"SeparatorRegion\")\n",
    "        #extract the Reading order of each Textregion\n",
    "        order = {x[\"regionRef\"]:x[\"index\"]for x in data.find_all(\"RegionRefIndexed\")} #this is already the sorted order beginning from order[0]\n",
    "   \n",
    "    number = fullname.split(\"/\")[-1].split(\".\")[0]\n",
    "    \n",
    "    #dictionary to get access to the coordinate of all lines of all textregions\n",
    "    textlines={}\n",
    "    for reg in regions:\n",
    "        for line in reg.find_all(\"TextLine\"):\n",
    "            if reg.get(\"id\") not in textlines:\n",
    "                textlines[reg.get(\"id\")] = [[line.get(\"id\"),line.find(\"Coords\")[\"points\"]]] \n",
    "            else: \n",
    "                textlines[reg.get(\"id\")].append([line.get(\"id\"),line.find(\"Coords\")[\"points\"]])\n",
    "                \n",
    "    #dictionary for all textregions and their coordinates\n",
    "    regs={}\n",
    "    for reg in regions:\n",
    "        regs[reg.get(\"id\")] = [reg.find(\"Coords\")[\"points\"],order[reg.get(\"id\")]]\n",
    "    \n",
    "    #list of all coordinate of the separators\n",
    "    separators=[]\n",
    "    for separ in separator_list:\n",
    "        separators.append(separ.find(\"Coords\")[\"points\"])\n",
    "        \n",
    "    #delete all too small wrong annotated regions\n",
    "    regs = delete_small(regs)\n",
    "    \n",
    "    #combined regions in one column\n",
    "    combined = combine_regions_in_column(regs,textlines)\n",
    "    \n",
    "    #get headlines\n",
    "    headers = possible_headline_multicolumn(regs, combined, textlines)\n",
    "    \n",
    "    #combine haedlines and first column\n",
    "    combined = combine_multicolumn_text_and_headlines(regs, combined, headers)\n",
    "    \n",
    "    #combine headlines and multiple columns\n",
    "    combined = combine_columns(regs, combined, headers, textlines, separators)\n",
    "    \n",
    "    img = cv2.imread(path + number + \".jpg\")\n",
    "    overlay = img.copy()\n",
    "\n",
    "    #1. draw the separators\n",
    "    for sep in separators:\n",
    "        start,end = get_start_end(sep)\n",
    "        \n",
    "        #draws a red rectangle arround the separator\n",
    "        img = cv2.rectangle(img, start, end, (0,0,255), -1)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    for k,v in regs.items():\n",
    "        \n",
    "        #v[0] is the coordinate list, v[1] is the reading order rank\n",
    "        start,end = get_start_end(v[0])\n",
    "\n",
    "\n",
    "        #assigns a random colour to each rectangle\n",
    "        col = tuple(random.randrange(256) for _ in range(3))\n",
    "        img = cv2.rectangle(img, start, end, col, -1)\n",
    "\n",
    "        #puts the reading order to the rectangles\n",
    "        \n",
    "        #img = cv2.putText(img, str(v[1]), (start[0]+5,start[1]+20),  cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "   \n",
    "    \"\"\"\n",
    "    #2. draw the Textregion rectangles\n",
    "    for k,v in combined.items():\n",
    "        \n",
    "        #get a random colour for each textregion\n",
    "        col = tuple(random.randrange(256) for _ in range(3))\n",
    "        textposition = (get_start_end(regs[v[0]][0]))        \n",
    "        \n",
    "        for reg in v:\n",
    "        \n",
    "            #v[0] is the coordinate list, v[1] is the reading order rank\n",
    "            start,end = get_start_end(regs[reg][0])\n",
    "\n",
    "            img = cv2.rectangle(img, start, end, col, -1)\n",
    "            \n",
    "            if reg not in textlines:\n",
    "                continue\n",
    "            else:\n",
    "                for line in textlines[reg]:\n",
    "                    s,e = get_start_end(line[1])\n",
    "                    \n",
    "                    #puts small red rectangles arround the textlines\n",
    "                    img = cv2.rectangle(img, s, e, (0,0,255), 1)\n",
    "                    \n",
    "        #3. put the reading order to the rectangles\n",
    "        img = cv2.putText(img, str(k), (textposition[0][0]+5, textposition[0][1]+25),  cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 4)\n",
    "    \n",
    "    \n",
    "    alpha =0.4\n",
    "    #creates a certain opacity for the rectanlge colours\n",
    "    img = cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    result = output + \"result_\" +number +\".jpg\"\n",
    "    print(result)\n",
    "    cv2.imwrite(result, img)\n",
    "    count +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1a436a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Further possibilities for improvement\n",
    "\n",
    "- improve article recognition across multiple columns (especially when an article continues in the next column and is no longer under the multi-column heading)\n",
    "- check in column if separator is in between paragraphs.\n",
    "- recognize and include images and free spaces on the page."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "articles",
   "language": "python",
   "name": "articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
